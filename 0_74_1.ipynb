{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "0.74-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Az-Ks/Zindi-Weekendz/blob/master/0_74_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6L7qEOXHiG_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls ../input/covid19-tweet-classification-challenge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "8yGrVTZziG_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('../input/covid19-tweet-classification-challenge/train (14).csv')\n",
        "test = pd.read_csv('../input/covid19-tweet-classification-challenge/test (10).csv')\n",
        "sampleSub = pd.read_csv('../input/covid19-tweet-classification-challenge/sample_sub (12).csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7CDQrJBxiG_Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "02f0cb09-6b74-4784-af4b-5598bfd91b07"
      },
      "source": [
        "import numpy as np\n",
        "print(np.shape(train))\n",
        "print(np.shape(test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6861, 3)\n",
            "(2941, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LCbBL2QviG_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.drop_duplicates(subset='text')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ijPAVOtRiG_e",
        "colab_type": "code",
        "colab": {},
        "outputId": "0f2c09d1-f352-4931-fd20-a4f2a836f986"
      },
      "source": [
        "np.shape(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5287, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "Oktgv64XiG_h",
        "colab_type": "code",
        "colab": {},
        "outputId": "ac1d676f-652b-4b0c-d31d-bbd0eb639c39"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID                                               text  target\n",
              "0  train_0            The bitcoin halving is cancelled due to       1\n",
              "1  train_1  MercyOfAllah In good times wrapped in its gran...       0\n",
              "2  train_2  266 Days No Digital India No Murder of e learn...       1\n",
              "3  train_3  India is likely to run out of the remaining RN...       1\n",
              "4  train_4  In these tough times the best way to grow is t...       0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>The bitcoin halving is cancelled due to</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>MercyOfAllah In good times wrapped in its gran...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>266 Days No Digital India No Murder of e learn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>India is likely to run out of the remaining RN...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>In these tough times the best way to grow is t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AhfPap4XiG_k",
        "colab_type": "code",
        "colab": {},
        "outputId": "eb56614e-eac0-48c2-d428-dc82436aebb8"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ID                                               text\n",
              "0  test_0  rinaldi According to the new Italian governmen...\n",
              "1  test_1  In 2017 a Palestinian judge banned divorce dur...\n",
              "2  test_2         Why is  explained in the video take a look\n",
              "3  test_3            Ed Davey fasting for Ramadan No contest\n",
              "4  test_4   Is Doja Cat good or do you just miss Nicki Minaj"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>rinaldi According to the new Italian governmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>In 2017 a Palestinian judge banned divorce dur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>Why is  explained in the video take a look</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>Ed Davey fasting for Ramadan No contest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>Is Doja Cat good or do you just miss Nicki Minaj</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TEgqTzj6iG_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([train,test], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v0Acy-B3iG_q",
        "colab_type": "code",
        "colab": {},
        "outputId": "449329e8-12c7-44fd-f851-62ccc9b92743"
      },
      "source": [
        "import pandas as pd\n",
        "#Stopwords list from https://github.com/Yoast/YoastSEO.js/blob/develop/src/config/stopwords.js\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "sentences = []\n",
        "labels = []\n",
        "for index, row in df.iterrows():\n",
        "    labels.append(row[2])\n",
        "    sentence = row[1]\n",
        "    for word in stopwords:\n",
        "        token = \" \" + word + \" \"\n",
        "        sentence = sentence.replace(token, \" \")\n",
        "        sentence = sentence.replace(\"  \", \" \")\n",
        "    sentences.append(sentence)\n",
        "\n",
        "print(len(sentences))\n",
        "print(sentences[0])\n",
        "x = pd.Series(sentences)\n",
        "df['Text'] = x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8228\n",
            "The bitcoin halving cancelled due to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tEi9uBJSiG_s",
        "colab_type": "code",
        "colab": {},
        "outputId": "a7245018-37b7-44dc-c105-9ace1aba6117"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID                                               text  target  \\\n",
              "0  train_0            The bitcoin halving is cancelled due to     1.0   \n",
              "1  train_1  MercyOfAllah In good times wrapped in its gran...     0.0   \n",
              "2  train_2  266 Days No Digital India No Murder of e learn...     1.0   \n",
              "3  train_3  India is likely to run out of the remaining RN...     1.0   \n",
              "4  train_4  In these tough times the best way to grow is t...     0.0   \n",
              "\n",
              "                                                Text  \n",
              "0               The bitcoin halving cancelled due to  \n",
              "1  MercyOfAllah In good times wrapped granular de...  \n",
              "2  266 Days No Digital India No Murder e learning...  \n",
              "3  India likely run remaining RNA kits essential ...  \n",
              "4  In tough times best way grow learn case teach ...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>The bitcoin halving is cancelled due to</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The bitcoin halving cancelled due to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>MercyOfAllah In good times wrapped in its gran...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MercyOfAllah In good times wrapped granular de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>266 Days No Digital India No Murder of e learn...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>266 Days No Digital India No Murder e learning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>India is likely to run out of the remaining RN...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>India likely run remaining RNA kits essential ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>In these tough times the best way to grow is t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>In tough times best way grow learn case teach ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WUgoHKrxiG_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['text'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aJcDNYfiiG_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text'] = df['Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EiIUfcZ-iG_0",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef61e643-cd2d-4017-a8ac-e9dd16f77fe1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  target                                               Text\n",
              "0  train_0     1.0               The bitcoin halving cancelled due to\n",
              "1  train_1     0.0  MercyOfAllah In good times wrapped granular de...\n",
              "2  train_2     1.0  266 Days No Digital India No Murder e learning...\n",
              "3  train_3     1.0  India likely run remaining RNA kits essential ...\n",
              "4  train_4     0.0  In tough times best way grow learn case teach ..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The bitcoin halving cancelled due to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MercyOfAllah In good times wrapped granular de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>266 Days No Digital India No Murder e learning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>India likely run remaining RNA kits essential ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>In tough times best way grow learn case teach ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "br8-37QdiG_2",
        "colab_type": "code",
        "colab": {},
        "outputId": "5ad00ee9-c3ca-423a-86c0-92d427fb873e"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "df[\"Text\"] = df[\"Text\"].apply(lemmatize_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /usr/share/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LZHFHIFBiG_4",
        "colab_type": "code",
        "colab": {},
        "outputId": "b4af1915-3e72-463b-dd37-485d86d5a2bd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  target                                               Text\n",
              "0  train_0     1.0        [The, bitcoin, halving, cancelled, due, to]\n",
              "1  train_1     0.0  [MercyOfAllah, In, good, time, wrapped, granul...\n",
              "2  train_2     1.0  [266, Days, No, Digital, India, No, Murder, e,...\n",
              "3  train_3     1.0  [India, likely, run, remaining, RNA, kit, esse...\n",
              "4  train_4     0.0  [In, tough, time, best, way, grow, learn, case..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[The, bitcoin, halving, cancelled, due, to]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[MercyOfAllah, In, good, time, wrapped, granul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[266, Days, No, Digital, India, No, Murder, e,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[India, likely, run, remaining, RNA, kit, esse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[In, tough, time, best, way, grow, learn, case...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "78n0LdtLiG_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert list of words to string (concat words with \" \")   \n",
        "def listToString(s):  \n",
        "    \n",
        "    str1 = \"\"  \n",
        "    \n",
        "    for ele in s:  \n",
        "        str1 += ele\n",
        "        if ele != s[len(s)-1]:\n",
        "          str1 += \" \"   \n",
        "    \n",
        "    return str1  \n",
        "df[\"Text\"] = df[\"Text\"].apply(listToString)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SeUg_8BYiG_9",
        "colab_type": "code",
        "colab": {},
        "outputId": "77702291-2e22-4fed-9040-3e8d27c95803"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  target                                               Text\n",
              "0  train_0     1.0               The bitcoin halving cancelled due to\n",
              "1  train_1     0.0  MercyOfAllah In good time wrapped granular det...\n",
              "2  train_2     1.0  266 Days No Digital India No Murder e learning...\n",
              "3  train_3     1.0  India likely run remaining RNA kit essential t...\n",
              "4  train_4     0.0  In tough time best way grow learn case teach h..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The bitcoin halving cancelled due to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MercyOfAllah In good time wrapped granular det...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>266 Days No Digital India No Murder e learning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>India likely run remaining RNA kit essential t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>In tough time best way grow learn case teach h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5RE2OJz3iG__",
        "colab_type": "code",
        "colab": {},
        "outputId": "d02cd81d-b478-4e4d-b07a-68897753bb00"
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID  target                                               Text\n",
              "0       train_0     1.0               The bitcoin halving cancelled due to\n",
              "1       train_1     0.0  MercyOfAllah In good time wrapped granular det...\n",
              "2       train_2     1.0  266 Days No Digital India No Murder e learning...\n",
              "3       train_3     1.0  India likely run remaining RNA kit essential t...\n",
              "4       train_4     0.0  In tough time best way grow learn case teach h...\n",
              "...         ...     ...                                                ...\n",
              "2936  test_2936     NaN  Along s 90 looking team jersey I love pic twit...\n",
              "2937  test_2937     NaN  The President will address nation key issue su...\n",
              "2938  test_2938     NaN  if anyone want dm talk abt dog cute animal sen...\n",
              "2939  test_2939     NaN  Boil EUCALYPTUS leaf tightly covered pot fille...\n",
              "2940  test_2940     NaN          Lazzari I ll talking sport w Tues AM 6 50\n",
              "\n",
              "[8228 rows x 3 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The bitcoin halving cancelled due to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MercyOfAllah In good time wrapped granular det...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>266 Days No Digital India No Murder e learning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>India likely run remaining RNA kit essential t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>In tough time best way grow learn case teach h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2936</th>\n",
              "      <td>test_2936</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Along s 90 looking team jersey I love pic twit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2937</th>\n",
              "      <td>test_2937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The President will address nation key issue su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2938</th>\n",
              "      <td>test_2938</td>\n",
              "      <td>NaN</td>\n",
              "      <td>if anyone want dm talk abt dog cute animal sen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2939</th>\n",
              "      <td>test_2939</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Boil EUCALYPTUS leaf tightly covered pot fille...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2940</th>\n",
              "      <td>test_2940</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lazzari I ll talking sport w Tues AM 6 50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8228 rows Ã— 3 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SGAy8cdIiHAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df[:5287]\n",
        "test = df[5287:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SQQ5YUTfiHAD",
        "colab_type": "code",
        "colab": {},
        "outputId": "93b18512-2565-4266-97ce-7ecc10f91652"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  target                                               Text\n",
              "0  train_0     1.0               The bitcoin halving cancelled due to\n",
              "1  train_1     0.0  MercyOfAllah In good time wrapped granular det...\n",
              "2  train_2     1.0  266 Days No Digital India No Murder e learning...\n",
              "3  train_3     1.0  India likely run remaining RNA kit essential t...\n",
              "4  train_4     0.0  In tough time best way grow learn case teach h..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The bitcoin halving cancelled due to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MercyOfAllah In good time wrapped granular det...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>266 Days No Digital India No Murder e learning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>India likely run remaining RNA kit essential t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>In tough time best way grow learn case teach h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E-ZFkL_0iHAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data to train and test \n",
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j9Ivd1VmiHAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "training_sentences = []\n",
        "testing_sentences = []\n",
        "validating_sentences = []\n",
        "\n",
        "for index, s in train.iterrows():\n",
        "  training_sentences.append(s[\"Text\"])\n",
        "\n",
        "for index, s in val.iterrows():\n",
        "  validating_sentences.append(s[\"Text\"])\n",
        "\n",
        "for index, s in test.iterrows():\n",
        "  testing_sentences.append(s[\"Text\"])\n",
        "  \n",
        "training_labels_final = train['target'].values.astype('float64')\n",
        "#testing_labels_final = test.drop([\"Text\"], axis=1).values.astype('float64')\n",
        "validating_labels_final = val['target'].values.astype('float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bXqSGE9ciHAI",
        "colab_type": "code",
        "colab": {},
        "outputId": "c3cd905a-44a6-4b74-915a-241732c3e76d"
      },
      "source": [
        "training_labels_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VIfaOtYOiHAK",
        "colab_type": "code",
        "colab": {},
        "outputId": "d1386dab-0ae1-4c9f-b2d2-33f981261254"
      },
      "source": [
        "print(len(training_sentences))\n",
        "print(len(training_labels_final))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4229\n",
            "4229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3bQg2378iHAO",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ceb8b8e-b026-4c5c-b615-52cda00b00b9"
      },
      "source": [
        "maxi = 0\n",
        "s=0\n",
        "for line in training_sentences:\n",
        "    line = line.split(' ')\n",
        "    s = s + len(line)\n",
        "    maxi = max(int(len(line)), maxi)\n",
        "print(maxi)\n",
        "print(s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49\n",
            "57825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vD_lYlHHiHAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 40000\n",
        "embedding_dim = 16\n",
        "max_length = 300\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "validating_sequences = tokenizer.texts_to_sequences(validating_sentences)\n",
        "validating_padded = pad_sequences(validating_sequences,maxlen=max_length)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RIJkH60LiHAS",
        "colab_type": "code",
        "colab": {},
        "outputId": "36946e38-ef5e-46cc-dee2-4dde235d860d"
      },
      "source": [
        "len(padded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4229"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B77L7C9ziHAU",
        "colab_type": "code",
        "colab": {},
        "outputId": "4fb44a5c-1397-4bf8-d2c9-c1da02a3ca99"
      },
      "source": [
        "len(training_labels_final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4229"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IX1gCXlqiHAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update tensorflow version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary() \n",
        "\n",
        "#fit the model\n",
        "num_epochs = 20\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(validating_padded, validating_labels_final))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sE5KXNwuiHAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(testing_padded)\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m-1BFaC2iHAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = []\n",
        "for x in predictions:\n",
        "    prediction.append(float(x))\n",
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4V99iwnJiHAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampleSub.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3XcDG_u5iHAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Submission\n",
        "submit = pd.DataFrame({'ID': sampleSub['ID'], 'target': prediction})\n",
        "from IPython.display import FileLink\n",
        "def create_submission(submission_file, submission_name):\n",
        "    submission_file.to_csv(submission_name+\".csv\" , index=False)\n",
        "    return FileLink(submission_name+\".csv\")\n",
        "create_submission(submit, 'submit')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWPJ8kpajKYK",
        "colab_type": "text"
      },
      "source": [
        "## **OTHER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uvrH8ZGCiHAl",
        "colab_type": "code",
        "colab": {},
        "outputId": "b2845f2d-f29b-45df-fc5d-88fd7a7f98be"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "msnYyssXiHAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtest = test['Text'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cIXVbJS7iHAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train['Text'].values, train['target'].values, \n",
        "                                                  stratify=train['target'].values, \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "01dgR_iSiHAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 300\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "xtest_seq = token.texts_to_sequences(xtest)\n",
        "\n",
        "# zero pad the sequences\n",
        "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "xtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)\n",
        "\n",
        "word_index = token.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l2M1zAHKiHAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE='../input/glove840b300dtxt/glove.840B.300d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7sXOViX3iHAw",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc90a979-1faf-45b8-b640-7b5c9e5e8a2c"
      },
      "source": [
        "# load the GloVe vectors in a dictionary:\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(EMBEDDING_FILE,encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.rstrip().rsplit(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2196017 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tGhh7O1yiHAx",
        "colab_type": "code",
        "colab": {},
        "outputId": "c63e2cb4-00e3-42da-bf79-cca1d2a3ba26"
      },
      "source": [
        "# create an embedding matrix for the words we have in the dataset\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11713/11713 [00:00<00:00, 218257.87it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z7u61rUiiHAz",
        "colab_type": "code",
        "colab": {},
        "outputId": "15a9f3e8-b9a1-46c1-bbd0-100890e8f240"
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11713"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d6Y7oiJ0iHA1",
        "colab_type": "code",
        "colab": {},
        "outputId": "aaca2eb5-b2ba-496a-b659-916ffac8073b"
      },
      "source": [
        "# Update tensorflow version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 300, 300)          3514200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 300, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              103424    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 4,828,649\n",
            "Trainable params: 1,314,449\n",
            "Non-trainable params: 3,514,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sN6aeqXaiHA3",
        "colab_type": "code",
        "colab": {},
        "outputId": "014d0067-0de9-4b11-8b25-fda7708f84fb"
      },
      "source": [
        "np.concatenate((training_labels_final,validating_labels_final))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., ..., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CpjkFe3viHA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(np.concatenate((padded,validating_padded)), np.concatenate((training_labels_final,validating_labels_final)), epochs=num_epochs, verbose=1) #, validation_data=(validating_padded, validating_labels_final))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-gTt2l5MiHA7",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb16085b-3c0f-4759-e339-66848d9df9d9"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "model.fit(padded, training_labels_final, epochs=num_epochs, verbose=1, validation_data=(validating_padded, validating_labels_final), callbacks=[earlystop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "5287/5287 [==============================] - 50s 10ms/step - loss: 1.5232\n",
            "Epoch 2/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.9013\n",
            "Epoch 3/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7692\n",
            "Epoch 4/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7484\n",
            "Epoch 5/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7549\n",
            "Epoch 6/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7502\n",
            "Epoch 7/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7395\n",
            "Epoch 8/20\n",
            "5287/5287 [==============================] - 50s 9ms/step - loss: 0.7469\n",
            "Epoch 9/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7493\n",
            "Epoch 10/20\n",
            "5287/5287 [==============================] - 48s 9ms/step - loss: 0.7501\n",
            "Epoch 11/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7463\n",
            "Epoch 12/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7389\n",
            "Epoch 13/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7434\n",
            "Epoch 14/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7311\n",
            "Epoch 15/20\n",
            "5287/5287 [==============================] - 48s 9ms/step - loss: 0.7245\n",
            "Epoch 16/20\n",
            "5287/5287 [==============================] - 48s 9ms/step - loss: 0.7246\n",
            "Epoch 17/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7119\n",
            "Epoch 18/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7163\n",
            "Epoch 19/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7081\n",
            "Epoch 20/20\n",
            "5287/5287 [==============================] - 49s 9ms/step - loss: 0.7171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5ee8099cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U-2wi-63iHA8",
        "colab_type": "code",
        "colab": {},
        "outputId": "1c8a3b63-9766-49dd-e130-e2f12801e578"
      },
      "source": [
        "predictions = model.predict(testing_padded)\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32697725],\n",
              "       [0.33219573],\n",
              "       [0.34695384],\n",
              "       ...,\n",
              "       [0.338429  ],\n",
              "       [0.3511871 ],\n",
              "       [0.3485684 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "a41JH8o3iHA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = []\n",
        "for x in predictions:\n",
        "    prediction.append(float(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "weJdJ1LyiHA_",
        "colab_type": "code",
        "colab": {},
        "outputId": "6aa889bd-0e9a-4b7c-b1d5-21aa4f77756f"
      },
      "source": [
        "#Submission\n",
        "submit = pd.DataFrame({'ID': sampleSub['ID'], 'target': prediction})\n",
        "from IPython.display import FileLink\n",
        "def create_submission(submission_file, submission_name):\n",
        "    submission_file.to_csv(submission_name+\".csv\" , index=False)\n",
        "    return FileLink(submission_name+\".csv\")\n",
        "create_submission(submit, 'submit')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/kaggle/working/submit.csv"
            ],
            "text/html": [
              "<a href='submit.csv' target='_blank'>submit.csv</a><br>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0lCGKBmtiHBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "3814d3f6-80d4-4a02-9c38-0a433b48a657"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@e3cdc2951d45.(none)')\n",
            "error: src refspec master does not match any.\n",
            "error: failed to push some refs to 'https://github.com/Az-Ks/ZINDI.git'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J4fM65wnWzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}